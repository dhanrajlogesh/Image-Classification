{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6d5119-e2f6-4d36-975f-70f2b0e7246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47371/1447100494.py:140: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "/home/dhanraj/.local/lib/python3.10/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/dhanraj/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_47371/1447100494.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "/home/dhanraj/.local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss=3.013132, LR=0.009961\n",
      "Epoch 2/50, Loss=2.422997, LR=0.009843\n",
      "Epoch 3/50, Loss=2.421217, LR=0.009649\n",
      "Epoch 4/50, Loss=2.382593, LR=0.009382\n",
      "Epoch 5/50, Loss=2.396114, LR=0.009045\n",
      "Epoch 10/50, Loss=2.266308, LR=0.006545\n",
      "Epoch 15/50, Loss=2.187725, LR=0.003455\n",
      "Epoch 20/50, Loss=2.275485, LR=0.000955\n",
      "Epoch 25/50, Loss=2.171755, LR=0.000000\n",
      "Epoch 30/50, Loss=2.148370, LR=0.000955\n",
      "Epoch 35/50, Loss=2.186818, LR=0.003455\n",
      "Epoch 40/50, Loss=2.243596, LR=0.006545\n",
      "Epoch 45/50, Loss=2.173289, LR=0.009045\n",
      "Epoch 50/50, Loss=2.245404, LR=0.010000\n",
      "Model saved to pixel_predictor_accum.pth\n",
      "\n",
      "=== TESTING ON MIDJOURNEY ===\n",
      "MidJourney Test Accuracy: 52.84%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real     0.5862    0.1504    0.2394       113\n",
      "   synthetic     0.5200    0.8966    0.6582       116\n",
      "\n",
      "    accuracy                         0.5284       229\n",
      "   macro avg     0.5531    0.5235    0.4488       229\n",
      "weighted avg     0.5527    0.5284    0.4516       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.cuda import amp\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_BINS = 64\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "ACCUMULATION_STEPS = 4\n",
    "MIDJOURNEY_BASE = \"/home/dhanraj/Documents/Midjourney_Exp2\"  # change to your path\n",
    "\n",
    "class PixelPredictor(nn.Module):\n",
    "    def __init__(self, num_bins=64):\n",
    "        super(PixelPredictor, self).__init__()\n",
    "        self.num_bins = num_bins\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.upsample1 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu_upsample1 = nn.ReLU()\n",
    "        self.final_conv = nn.Conv2d(64, num_bins, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = self.relu_upsample1(self.bn3(self.upsample1(x)))\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# ===== UTILS =====\n",
    "def rgb_to_grayscale(img):\n",
    "    weights = torch.tensor([0.2989, 0.5870, 0.1140], device=img.device).view(1, 3, 1, 1)\n",
    "    return (img * weights).sum(dim=1)\n",
    "\n",
    "def quantize_targets(gray_img, num_bins=64):\n",
    "    bins = torch.linspace(0, 256, steps=num_bins + 1, device=gray_img.device)\n",
    "    target_bins = torch.bucketize((gray_img * 255).long(), bins) - 1\n",
    "    return target_bins.clamp(0, num_bins - 1)\n",
    "\n",
    "def downsample(img, levels=3):\n",
    "    downs = [img]\n",
    "    for _ in range(levels):\n",
    "        img = F.avg_pool2d(img, 2, 2)\n",
    "        downs.append(img)\n",
    "    return downs\n",
    "\n",
    "def compute_entropy(probs):\n",
    "    return -torch.sum(probs * torch.log(probs + 1e-8), dim=1)\n",
    "\n",
    "def compute_nll(probs, targets):\n",
    "    return -torch.log(torch.gather(probs, 1, targets.unsqueeze(1)).squeeze(1) + 1e-8)\n",
    "\n",
    "def extract_features(model, img_tensor, num_bins=64):\n",
    "    model.eval()\n",
    "    downs = downsample(img_tensor)\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(3):\n",
    "            high = downs[i]\n",
    "            low = F.interpolate(downs[i + 1], scale_factor=2, mode='nearest')\n",
    "            logits = model(low)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            gray_high = rgb_to_grayscale(high)\n",
    "            target = quantize_targets(gray_high, num_bins=num_bins)\n",
    "            entropy = compute_entropy(probs)\n",
    "            nll = compute_nll(probs, target)\n",
    "            gap = nll.mean().item() - entropy.mean().item()\n",
    "            features.append((nll.mean().item(), entropy.mean().item(), gap))\n",
    "    D0, D1 = features[0][2], features[1][2]\n",
    "    return {'D0': D0, 'D1': D1, 'delta01': D0 - D1,\n",
    "            'abs_D0': abs(D0), 'abs_delta01': abs(D0 - D1)}\n",
    "\n",
    "def classify_image(features, delta01_threshold=0.1):\n",
    "    return 'synthetic' if abs(features['delta01']) > delta01_threshold else 'real'\n",
    "\n",
    "\n",
    "transform_train = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(15),\n",
    "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "cifar_train = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_indices = list(range(2000))\n",
    "train_dataset = Subset(cifar_train, train_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "class MidJourneyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dir, split='test', transform=None, max_samples_per_class=200):\n",
    "        self.real_dir = os.path.join(base_dir, split, 'REAL')\n",
    "        self.fake_dir = os.path.join(base_dir, split, 'FAKE')\n",
    "        self.transform = transform\n",
    "        self.real_files = [os.path.join(self.real_dir, f) for f in os.listdir(self.real_dir)\n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:max_samples_per_class]\n",
    "        self.fake_files = [os.path.join(self.fake_dir, f) for f in os.listdir(self.fake_dir)\n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:max_samples_per_class]\n",
    "        self.files = self.real_files + self.fake_files\n",
    "        self.labels = [0]*len(self.real_files) + [1]*len(self.fake_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx]).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "mid_test_dataset = MidJourneyDataset(MIDJOURNEY_BASE, split='test', transform=transform_test)\n",
    "mid_test_loader = DataLoader(mid_test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                             num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "def train_model_with_accumulation(model, train_loader, device, epochs=50, accumulation_steps=4):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs//2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        for batch_idx, (imgs, _) in enumerate(train_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            low_res = F.avg_pool2d(imgs, 2, 2)\n",
    "            gray_imgs = rgb_to_grayscale(imgs)\n",
    "            targets = quantize_targets(gray_imgs, num_bins=model.num_bins)\n",
    "\n",
    "            with amp.autocast():\n",
    "                logits = model(low_res)\n",
    "                loss = criterion(logits, targets) / accumulation_steps\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item() * accumulation_steps\n",
    "\n",
    "        scheduler.step()\n",
    "        if epoch % 5 == 0 or epoch <= 5:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss={total_loss/len(train_loader):.6f}, LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "\n",
    "def save_model(model, path=\"pixel_predictor_accum.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(path=\"pixel_predictor_accum.pth\"):\n",
    "    model = PixelPredictor(num_bins=NUM_BINS)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device).eval()\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== TRAINING ===\")\n",
    "    model = PixelPredictor(num_bins=NUM_BINS)\n",
    "    train_model_with_accumulation(model, train_loader, device,\n",
    "                                  epochs=EPOCHS, accumulation_steps=ACCUMULATION_STEPS)\n",
    "    save_model(model)\n",
    "\n",
    "    print(\"\\n=== TESTING ON MIDJOURNEY ===\")\n",
    "    y_true, y_pred = [], []\n",
    "    for imgs, labels in mid_test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        for i in range(imgs.size(0)):\n",
    "            feats = extract_features(model, imgs[i].unsqueeze(0), num_bins=NUM_BINS)\n",
    "            pred = classify_image(feats, delta01_threshold=0.1)\n",
    "            y_pred.append(pred)\n",
    "            y_true.append('real' if labels[i] == 0 else 'synthetic')\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"MidJourney Test Accuracy: {acc*100:.2f}%\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81345263-de72-4c0d-b178-6f0581dbf8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
